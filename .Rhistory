geom_tile(aes(fill=value, alpha=value)) +
geom_contour(aes(z=value), color='white', size=0.1) +
scale_fill_gradient(low='grey', high='steelblue', guide=FALSE) +
scale_alpha(guide=FALSE) +
theme(legend.position='None') + theme_bw() +
ggtitle(paste0('corr=',corr)) + xlab('y1') + ylab('y2')
# graph
density.mvn %>%
ggplot(aes(x=Var1, y=Var2)) +
geom_tile(aes(fill=value, alpha=value)) +
geom_contour(aes(z=value), color='white', size=0.1) +
scale_fill_gradient(low='grey', high='steelblue', guide=FALSE) +
scale_alpha(guide=FALSE) +
theme(legend.position='None') + theme_bw()
abline(0,1)
getwd()
### 2. Draw yourself Figure 7.2
source("data/hdr2d.R")
plot.hdr2d(THETA,xlab=expression(theta[1]),ylab=expression(theta[2]) )
abline(0,1)
mean( THETA[,2]-THETA[,1])
mean( THETA[,2]>THETA[,1])
quantile(  SIGMA[,2]/sqrt(SIGMA[,1]*SIGMA[,4]), prob=c(.025,.5,.975) )
quantile(   THETA[,2]-THETA[,1], prob=c(.025,.5,.975) )
plot.hdr2d()
plot.hdr2d(
plot.hdr2d
THETA %>% View
rownames(THETA) <- 1:sample.size
THETA
# Load Data
test <- matrix(c(59, 43, 34, 32, 42, 38, 55, 67, 64, 45, 49, 72, 34,
70, 34, 50, 41, 52, 60, 34, 28, 35, 77, 39, 46, 26, 38, 43, 68,
86, 77, 60, 50, 59, 38, 48, 55, 58, 54, 60, 75, 47, 48, 33), ncol=2, byrow=FALSE)
colnames(test) <- c('pretest','posttest')
# Preparing
n <- nrow(test)
ybar <- colMeans(test)
Sigma <- cov(test)
THETA <- NULL
SIGMA <- NULL
inv <- solve
sample.size = 5000
sample.new = NULL
# prior
mu0 <- c(50,50); nu0 <- 4 #(nu0 = p+2 = 4)
S0 <- L0 <- matrix(c(625,312.5,312.5,625), nrow=2, ncol=2)
set.seed(2021)
for(i in 1:sample.size){
# update theta
Ln = inv(inv(L0) + n*inv(Sigma))
mun = Ln %*% (inv(L0)%*%mu0 + n*inv(Sigma)%*%ybar)
theta = mvrnorm(1, mun, Ln)
# update sigma
Sn = S0 + (t(test)-theta)%*%t(t(test)-theta)
Sigma = inv(rWishart(1, nu0+n, inv(Sn))[,,1])
# Save results
THETA <- rbind(THETA, theta)
SIGMA <- rbind(SIGMA, c(Sigma))
# sample new
sample.new = rbind(sample.new, mvrnorm(n=1, mu=theta, Sigma=Sigma))
}
rownames(THETA) <- 1:sample.size
rownames(SIGMA) <- 1:sample.size
THETA %>% View
plot.hdr2d(THETA,xlab=expression(theta[1]),ylab=expression(theta[2]) )
require(ash)
install.packages('ash')
library(ash)
library(ash)
require(ash)
install.packages('ash')
library(ash)
require(ash)
plot.hdr2d(THETA,xlab=expression(theta[1]),ylab=expression(theta[2]) )
plot.hdr2d(YS,xlab=expression(italic(y[1])),ylab=expression(italic(y[2])),
xlim=c(0,100),ylim=c(0,100) )
plot.hdr2d(samples.new,xlab=expression(italic(y[1])),ylab=expression(italic(y[2])),
xlim=c(0,100),ylim=c(0,100) )
plot.hdr2d(samplesnew,xlab=expression(italic(y[1])),ylab=expression(italic(y[2])),
xlim=c(0,100),ylim=c(0,100) )
plot.hdr2d(sample.new,xlab=expression(italic(y[1])),ylab=expression(italic(y[2])),
xlim=c(0,100),ylim=c(0,100) )
points(Y[,1],Y[,2],pch=16,cex=.7)
points(test[,1],test[,2],pch=16,cex=.7)
abline(0,1)
# graph
par(mfrow=c(1,2),mgp=c(1.75,.75,0),mar=c(3,3,1,1))
plot.hdr2d(THETA,xlab=expression(theta[1]),ylab=expression(theta[2]) )
abline(0,1)
plot.hdr2d(sample.new,xlab=expression(italic(y[1])),ylab=expression(italic(y[2])),
xlim=c(0,100),ylim=c(0,100) )
points(test[,1],test[,2],pch=16,cex=.7)
abline(0,1)
# graph
Theta
rm(list=ls())
# Load Data
test <- matrix(c(59, 43, 34, 32, 42, 38, 55, 67, 64, 45, 49, 72, 34,
70, 34, 50, 41, 52, 60, 34, 28, 35, 77, 39, 46, 26, 38, 43, 68,
86, 77, 60, 50, 59, 38, 48, 55, 58, 54, 60, 75, 47, 48, 33), ncol=2, byrow=FALSE)
colnames(test) <- c('pretest','posttest')
# Preparing
n <- nrow(test)
ybar <- colMeans(test)
Sigma <- cov(test)
THETA <- NULL
SIGMA <- NULL
inv <- solve
sample.size = 5000
sample.new = NULL
# prior
mu0 <- c(50,50); nu0 <- 4 #(nu0 = p+2 = 4)
S0 <- L0 <- matrix(c(625,312.5,312.5,625), nrow=2, ncol=2)
set.seed(2021)
for(i in 1:sample.size){
# update theta
Ln = inv(inv(L0) + n*inv(Sigma))
mun = Ln %*% (inv(L0)%*%mu0 + n*inv(Sigma)%*%ybar)
theta = mvrnorm(1, mun, Ln)
# update sigma
Sn = S0 + (t(test)-theta)%*%t(t(test)-theta)
Sigma = inv(rWishart(1, nu0+n, inv(Sn))[,,1])
# Save results
THETA <- rbind(THETA, theta)
SIGMA <- rbind(SIGMA, c(Sigma))
# sample new
sample.new = rbind(sample.new, mvrnorm(n=1, mu=theta, Sigma=Sigma))
}
rownames(THETA) <- 1:sample.size
rownames(SIGMA) <- 1:sample.size
# graph
Theta
# graph
THETA
# graph
names(THETA)
# graph
namesdata.frame(THETA)()
# graph
names(data.frame(THETA))
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point()
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='orange')
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='green')
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='darkgreen')
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='oragne')
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='orange')
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0)
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) + coord_fixed(ratio=1)
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) + coord_fixed(ratio=2)
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) + coord_fixed(ratio=3)
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) + geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) + coord_fixed(ratio=1)
# graph
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
coord_fixed(ratio=1) +
ggtitle('Posterior draws of Mu')
sample.new
data.frame(sample.new)
names(data.frame(sample.new))
data.frame(sample.new) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
coord_fixed(ratio=1) +
ggtitle('Posterior Predictive')
data.frame(sample.new) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
# coord_fixed(ratio=1) +
ggtitle('Posterior Predictive')
grid.arrange(p1, p2, nrow=1)
# graph
p1 <- data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
ggtitle('Posterior draws of Mu')
p2 <- data.frame(sample.new) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
ggtitle('Posterior Predictive')
grid.arrange(p1, p2, nrow=1)
# graph(ggplot 활용)
p1 <- data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(theta)) +
ggtitle('Posterior draws of Mu')
# graph(ggplot 활용)
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(theta)) +
ggtitle('Posterior draws of Mu')
# graph(ggplot 활용)
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(theta_1)) +
ggtitle('Posterior draws of Mu')
# graph(ggplot 활용)
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(theta)_1) +
ggtitle('Posterior draws of Mu')
# graph(ggplot 활용)
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(theta)_1) +
ggtitle('Posterior draws of Mu')
# graph(ggplot 활용)
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(theta[1])) +
ggtitle('Posterior draws of Mu')
# graph(ggplot 활용)
data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(theta[1])) + ylab(expression(theta[2])) +
ggtitle('Posterior draws of Mu')
p2 <- data.frame(sample.new) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(y[1])) + ylab(expression(y[2])) +
ggtitle('Posterior Predictive')
grid.arrange(p1, p2, nrow=1)
# graph(ggplot 활용)
p1 <- data.frame(THETA) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(theta[1])) + ylab(expression(theta[2])) +
ggtitle('Posterior draws of Mu')
p2 <- data.frame(sample.new) %>%
ggplot(aes(x=pretest, y=posttest)) +
geom_point(size=1, color='orange') +
geom_abline(slope=1, intercept=0) +
xlab(expression(y[1])) + ylab(expression(y[2])) +
ggtitle('Posterior Predictive')
grid.arrange(p1, p2, nrow=1)
grid.arrange(p1, p2, nrow=1) +
ggtitle('Reading Comprehension')
grid.arrange(p1, p2, nrow=1)
install.packages('rmd2jupyter')
getwd()
library(rmd2jupyter)
rmd2jupyter('new.Rmd')
#### Diabetes example
load("diabetes.RData")
yf<-diabetes$y
yf<-(yf-mean(yf))/sd(yf)
Xf<-diabetes$X
Xf<-t( (t(Xf)-apply(Xf,2,mean))/apply(Xf,2,sd))
## set up training and test data
n<-length(yf)
set.seed(1)
i.te<-sample(1:n,100)
i.tr<-(1:n)[-i.te]
y<-yf[i.tr] ; y.te<-yf[i.te]
X<-Xf[i.tr,]; X.te<-Xf[i.te,]
#### Bayesian model selection
p<-dim(X)[2]
S<-10000
source("regression_gprior.R")
## Don't run it again if you've already run it
runmcmc<-!any(system("ls",intern=TRUE)=="diabetesBMA.RData")
if(!runmcmc){ load("diabetesBMA.RData") }
if(runmcmc){
BETA<-Z<-matrix(NA,S,p)
z<-rep(1,dim(X)[2] )
lpy.c<-lpy.X(y,X[,z==1,drop=FALSE])
for(s in 1:S)
{
for(j in sample(1:p))
{
zp<-z ; zp[j]<-1-zp[j]
lpy.p<-lpy.X(y,X[,zp==1,drop=FALSE])
r<- (lpy.p - lpy.c)*(-1)^(zp[j]==0)
z[j]<-rbinom(1,1,1/(1+exp(-r)))
if(z[j]==zp[j]) {lpy.c<-lpy.p}
}
beta<-z
if(sum(z)>0){beta[z==1]<-lm.gprior(y,X[,z==1,drop=FALSE],S=1)$beta }
Z[s,]<-z
BETA[s,]<-beta
if(s%%10==0)
{
bpm<-apply(BETA[1:s,],2,mean) ; plot(bpm)
cat(s,mean(z), mean( (y.te-X.te%*%bpm)^2),"\n")
Zcp<- apply(Z[1:s,,drop=FALSE],2,cumsum)/(1:s)
plot(c(1,s),range(Zcp),type="n") ; apply(Zcp,2,lines)
}
}
save(BETA,Z,file="diabetesBMA.RData")
}
#### Figure 9.7
par(mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
beta.bma<-apply(BETA,2,mean,na.rm=TRUE)
y.te.bma<-X.te%*%beta.bma
mean( (y.te-y.te.bma)^2)
layout( matrix(c(1,1,2),nrow=1,ncol=3) )
plot(apply(Z,2,mean,na.rm=TRUE),xlab="regressor index",ylab=expression(
paste( "Pr(",italic(z[j] == 1),"|",italic(y),",X)",sep="")),type="h",lwd=2)
plot(y.te,y.te.bma,xlab=expression(italic(y)[test]),
ylab=expression(hat(italic(y))[test])) ; abline(0,1)
rm(list=ls())
library(knitr)
knit('bayes_week5.Rmd')
?knit
knit('bayes_week5.Rmd', output = 'pdf_document')
?knit
diabetes
diabetes
View(diabetes)
diabetes[["X"]]
diabetes$X
dim(diabetes$X)
View(diabetes$X)
write.csv(diabetes$X, file = 'diabetes.x')
write.csv(diabetes$X, file = 'diabetes_x.csv')
write.csv(diabetes$y, file = 'diabetes_y.csv')
#### Diabetes example
load("data/diabetes.RData")
yf<-diabetes$y
yf<-(yf-mean(yf))/sd(yf)
Xf<-diabetes$X
Xf<-t( (t(Xf)-apply(Xf,2,mean))/apply(Xf,2,sd))
# Train-Test split
## set up training and test data
n<-length(yf)
set.seed(1)
i.te<-sample(1:n,100)
i.tr<-(1:n)[-i.te]
y<-yf[i.tr] ; y.te<-yf[i.te]
X<-Xf[i.tr,]; X.te<-Xf[i.te,]
#### Diabetes example
load("data/diabetes.RData")
yf<-diabetes$y
yf<-(yf-mean(yf))/sd(yf)
Xf<-diabetes$X
Xf<-t( (t(Xf)-apply(Xf,2,mean))/apply(Xf,2,sd))
# Train-Test split
## set up training and test data
n<-length(yf)
set.seed(1)
i.te<-sample(1:n,100)
i.tr<-(1:n)[-i.te]
y<-yf[i.tr] ; y.te<-yf[i.te]
X<-Xf[i.tr,]; X.te<-Xf[i.te,]
# Bayesian Model Selection
#### Bayesian model selection
p<-dim(X)[2]
S<-10000
# source("regression_gprior.R")
lm.gprior<-function(y,X,g=dim(X)[1],nu0=1,s20=try(summary(lm(y~-1+X))$sigma^2,silent=TRUE),S=1000)
{
n<-dim(X)[1] ; p<-dim(X)[2]
Hg<- (g/(g+1)) * X%*%solve(t(X)%*%X)%*%t(X)
SSRg<- t(y)%*%( diag(1,nrow=n)  - Hg ) %*%y
s2<-1/rgamma(S, (nu0+n)/2, (nu0*s20+SSRg)/2 )
Vb<- g*solve(t(X)%*%X)/(g+1)
Eb<- Vb%*%t(X)%*%y
E<-matrix(rnorm(S*p,0,sqrt(s2)),S,p)
beta<-t(  t(E%*%chol(Vb)) +c(Eb))
list(beta=beta,s2=s2)
}
lmratio.gprior<-function(z0,z1,y,X,g=dim(X)[1],nu0=1,
s200=mean( lm(y~-1+X[,z0==1])$res^2),
s201=mean( lm(y~-1+X[,z1==1])$res^2) )
{
n<-dim(X)[1]
X0<-X[,z0==1]
X1<-X[,z1==1]
H0<- (g/(g+1)) * X0%*%solve(t(X0)%*%X0)%*%t(X0)
SS0<- t(y)%*%( diag(1,nrow=n)  - H0 ) %*%y
p0<-sum(z0==1)
H1<- (g/(g+1)) * X1%*%solve(t(X1)%*%X1)%*%t(X1)
SS1<- t(y)%*%( diag(1,nrow=n)  - H1 ) %*%y
p1<-sum(z1==1)
-.5*(p1-p0)*log( 2*pi*(1+g))  +
.5*nu0*log(s201/s200) + .5*(nu0+n)*log( (nu0*s200+SS0)/(nu0+s201+SS1) )
}
mselect.gprior<-function(y,X,S=500*dim(X)[2],verb=FALSE)
{
Z<-NULL
z<-rep(1,dim(X)[2] )
for(s in 1:S)
{
for(j in sample(1:p))
{
z1<-z0<-z  ; z1[j]<-1 ; z0[j]<-0
r<-lmratio.gprior(z0,z1,y,X)
z[j]<-rbinom(1,1,1/(1+exp(-r)))
}
Z<-rbind(Z,z)
if(verb==TRUE) {cat(s,mean(z),"\n") }
}
Z
}
lpy.X<-function(y,X,
g=length(y),nu0=1,s20=try(summary(lm(y~-1+X))$sigma^2,silent=TRUE))
{
n<-dim(X)[1] ; p<-dim(X)[2]
if(p==0) { s20<-mean(y^2) }
H0<-0 ; if(p>0) { H0<- (g/(g+1)) * X%*%solve(t(X)%*%X)%*%t(X) }
SS0<- t(y)%*%( diag(1,nrow=n)  - H0 ) %*%y
-.5*n*log(2*pi) +lgamma(.5*(nu0+n)) - lgamma(.5*nu0)  - .5*p*log(1+g) +
.5*nu0*log(.5*nu0*s20) -.5*(nu0+n)*log(.5*(nu0*s20+SS0))
}
####
mselect.gprior<-function(y,X,S=500*dim(X)[2],verb=FALSE)
{
Z<-NULL
z<-rep(1,dim(X)[2] )
for(s in 1:S)
{
for(j in sample(1:p))
{
z1<-z0<-z  ; z1[j]<-1 ; z0[j]<-0
r<-lmratio.gprior(z0,z1,y,X)
z[j]<-rbinom(1,1,1/(1+exp(-r)))
}
Z<-rbind(Z,z)
if(verb==TRUE) {cat(s,mean(z),"\n") }
}
Z
}
```
## Don't run it again if you've already run it
runmcmc<-!any(system("ls",intern=TRUE)=="data/diabetesBMA.RData")
if(!runmcmc){ load("data/diabetesBMA.RData") }
if(runmcmc){
BETA<-Z<-matrix(NA,S,p)
z<-rep(1,dim(X)[2] )
lpy.c<-lpy.X(y,X[,z==1,drop=FALSE])
for(s in 1:S)
{
for(j in sample(1:p))
{
zp<-z ; zp[j]<-1-zp[j]
lpy.p<-lpy.X(y,X[,zp==1,drop=FALSE])
r<- (lpy.p - lpy.c)*(-1)^(zp[j]==0)
z[j]<-rbinom(1,1,1/(1+exp(-r)))
if(z[j]==zp[j]) {lpy.c<-lpy.p}
}
beta<-z
if(sum(z)>0){beta[z==1]<-lm.gprior(y,X[,z==1,drop=FALSE],S=1)$beta }
Z[s,]<-z
BETA[s,]<-beta
if(s%%10==0)
{
bpm<-apply(BETA[1:s,],2,mean) ; plot(bpm)
cat(s,mean(z), mean( (y.te-X.te%*%bpm)^2),"\n")
Zcp<- apply(Z[1:s,,drop=FALSE],2,cumsum)/(1:s)
plot(c(1,s),range(Zcp),type="n") ; apply(Zcp,2,lines)
}
}
save(BETA,Z,file="diabetesBMA.RData")
}
par(mar=c(2.75,2.75,.5,.5),mgp=c(1.7,.7,0))
beta.bma<-apply(BETA,2,mean,na.rm=TRUE)
y.te.bma<-X.te%*%beta.bma
mean( (y.te-y.te.bma)^2)
layout( matrix(c(1,1,2),nrow=1,ncol=3) )
plot(apply(Z,2,mean,na.rm=TRUE),xlab="regressor index",ylab=expression(
paste( "Pr(",italic(z[j] == 1),"|",italic(y),",X)",sep="")),type="h",lwd=2)
plot(y.te,y.te.bma,xlab=expression(italic(y)[test]),
ylab=expression(hat(italic(y))[test])) ; abline(0,1)
